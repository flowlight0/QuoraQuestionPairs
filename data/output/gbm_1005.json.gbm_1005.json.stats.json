{
    "config": {
        "data_prefix": "data/input/",
        "features": [
            0,
            1,
            2,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            16,
            18,
            21,
            22,
            28,
            30,
            31,
            32,
            44,
            45,
            46,
            47,
            75,
            76,
            77,
            78,
            79,
            80,
            81,
            82,
            83,
            84,
            85,
            86,
            91,
            92,
            93,
            109,
            110,
            111,
            112,
            117,
            118,
            119,
            145,
            146,
            152,
            153,
            154,
            155,
            156,
            157,
            158,
            159,
            160,
            161,
            162,
            163,
            164,
            165,
            166,
            167,
            168,
            1000,
            1001,
            1002,
            1010
        ],
        "model": {
            "params": {
                "booster": {
                    "bagging_fraction": 0.7,
                    "bagging_freq": 5,
                    "bagging_seed": 3,
                    "categorical_column": [],
                    "feature_fraction": 0.7,
                    "feature_fraction_seed": 2,
                    "learning_rate": 0.02,
                    "max_bin": 255,
                    "metric": "binary_logloss",
                    "num_leaves": 256,
                    "objective": "binary",
                    "task": "train",
                    "verbose": 1
                },
                "train": {
                    "early_stopping_rounds": 50,
                    "num_boost_round": 1000,
                    "verbose_eval": 10
                }
            },
            "path": "models/2_lightgbm.py",
            "target_positive_ratio": 0.17426506525171756
        }
    },
    "feature_importance": {
        "dep_2grams_common_ratio_stop": 3282,
        "dep_2grams_stop_sum_tfidf_q1": 3079,
        "dep_2grams_stop_sum_tfidf_q2": 3173,
        "dep_2grams_stop_tfidf_cosine": 3451,
        "dep_2grams_sum_tfidf_q1": 2575,
        "dep_2grams_sum_tfidf_q2": 2790,
        "dep_2grams_tfidf_cosine": 4100,
        "dep_depth_limit_in_q1_words_ratio_glove": 169,
        "dep_depth_limit_in_q2_words_ratio_glove": 127,
        "dep_depth_limit_wmd_glove": 5061,
        "f0": 3064,
        "f1": 3948,
        "f10": 1976,
        "f109": 2908,
        "f11": 3258,
        "f110": 893,
        "f111": 4198,
        "f112": 3596,
        "f117.q1_freq": 1089,
        "f117.q2_freq": 999,
        "f118": 5208,
        "f119": 3740,
        "f12": 1779,
        "f13": 3296,
        "f14": 1236,
        "f145": 518,
        "f146": 1626,
        "f152": 1269,
        "f153": 1816,
        "f154": 2410,
        "f155": 2567,
        "f156": 1765,
        "f157": 976,
        "f158": 803,
        "f159": 3804,
        "f16": 2570,
        "f160": 4226,
        "f161": 2480,
        "f162": 1606,
        "f163": 3153,
        "f164": 2590,
        "f165": 3238,
        "f166": 4236,
        "f167": 4134,
        "f168": 3415,
        "f18": 2475,
        "f2": 462,
        "f21": 2177,
        "f22": 2658,
        "f28": 3906,
        "f30": 572,
        "f31": 2939,
        "f32": 3130,
        "f4": 2170,
        "f44": 4132,
        "f45": 4033,
        "f46": 3468,
        "f47": 753,
        "f5": 2386,
        "f6": 3058,
        "f7": 850,
        "f75": 2401,
        "f76": 2402,
        "f77": 3532,
        "f78": 3304,
        "f79": 3107,
        "f8": 922,
        "f80": 3238,
        "f81": 2918,
        "f82": 3005,
        "f83": 2113,
        "f84": 2008,
        "f85": 1344,
        "f86": 1527,
        "f9": 1769,
        "f91": 3998,
        "f92": 4627,
        "f93": 3144
    },
    "results": {
        "accuracy": 0.9359603575779191,
        "auc": 0.9711298718620729,
        "f1_score": 0.8047650817466242,
        "log_loss": 0.1526468691920268,
        "precision": 0.8584779304280314,
        "pred_mean": 0.18433660169341412,
        "recall": 0.7573778179747429,
        "train_log_loss": 0.08969562861509782
    }
}
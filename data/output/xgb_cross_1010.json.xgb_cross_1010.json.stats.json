{
    "config": {
        "data_prefix": "data/input/",
        "features": [
            0,
            1,
            2,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            16,
            18,
            21,
            22,
            28,
            30,
            31,
            32,
            44,
            45,
            46,
            47,
            57,
            60,
            64,
            75,
            76,
            77,
            78,
            79,
            80,
            81,
            82,
            83,
            84,
            85,
            86,
            91,
            92,
            93,
            109,
            110,
            111,
            112,
            117,
            118,
            119,
            137,
            145,
            146,
            151,
            152,
            153,
            154,
            155,
            156,
            157,
            158,
            159,
            160,
            161,
            162,
            163,
            164,
            165,
            166,
            167,
            168,
            1000,
            1001,
            1002,
            1003,
            1004,
            1005,
            1006,
            1007,
            1008,
            1013,
            1018,
            1026,
            1027,
            1028,
            1029,
            1030
        ],
        "model": {
            "params": {
                "booster": {
                    "colsample_bytree": 0.5,
                    "eta": 0.02,
                    "eval_metric": "logloss",
                    "gamma": 1,
                    "lambda": 0.1,
                    "max_depth": 7,
                    "min_child_weight": 100,
                    "objective": "binary:logistic",
                    "seed": 87978979,
                    "silent": 0,
                    "subsample": 0.7
                },
                "train": {
                    "early_stopping_rounds": 50,
                    "num_boost_round": 3000,
                    "verbose_eval": 50
                }
            },
            "path": "models/1000_xgb_cross.py",
            "target_positive_ratio": 0.17426506525171756
        },
        "takapt_features": [
            "z_noun_match",
            "z_word_match",
            "z_word_match_idf",
            "z_n_sim",
            "common_words_lemm",
            "n_sim_lemm",
            "n_sim_lemm_stop",
            "s2v_sum_dist",
            "s2v_ave_dist",
            "sum_prob_weight_common_words",
            "sum_prob_weight_uncommon_words",
            "top_similarity",
            "min_sim",
            "max_sim",
            "common_bigrams_clean_lemm",
            "jaccard_common_bigrams_clean_lemm",
            "nazo_common_bigrams_clean_lemm",
            "sum_weight_common_bigrams",
            "sum_weight_common_bigrams_limit3",
            "common_ngrams_clean_lemm",
            "jaccard_common_ngrams_clean_lemm",
            "nazo_common_ngrams_clean_lemm",
            "clean_lemm_wmd",
            "bleu_clean_lemm_stem_q1q2",
            "bleu_clean_lemm_stem_q2q1",
            "bleu_clean_lemm_q1q2",
            "bleu_clean_lemm_q2q1",
            "norm_sum_prob_weight_common_words",
            "sum_prob_weight_common_words_thresh_0.20",
            "sum_prob_weight_common_words_thresh_0.30",
            "sum_prob_weight_common_words_thresh_0.40",
            "sum_prob_weight_common_words_thresh_0.50",
            "sum_prob_weight_common_words_thresh_0.60",
            "sum_prob_weight_common_words_thresh_0.70",
            "sum_prob_weight_common_words_thresh_0.80",
            "sum_prob_weight_common_words_thresh_0.90",
            "sum_prob_weight_common_words_thresh_0.95",
            "sum_prob_weight_uncommon_words_thresh_0.20",
            "sum_prob_weight_uncommon_words_thresh_0.30",
            "sum_prob_weight_uncommon_words_thresh_0.40",
            "sum_prob_weight_uncommon_words_thresh_0.50",
            "sum_prob_weight_uncommon_words_thresh_0.60",
            "sum_prob_weight_uncommon_words_thresh_0.70",
            "sum_prob_weight_uncommon_words_thresh_0.80",
            "sum_prob_weight_uncommon_words_thresh_0.90",
            "sum_prob_weight_uncommon_words_thresh_0.95",
            "sum_prob_weight_common_words_spacy_thresh_0.20",
            "sum_prob_weight_common_words_spacy_thresh_0.30",
            "sum_prob_weight_common_words_spacy_thresh_0.40",
            "sum_prob_weight_common_words_spacy_thresh_0.50",
            "sum_prob_weight_common_words_spacy_thresh_0.60",
            "sum_prob_weight_common_words_spacy_thresh_0.70",
            "sum_prob_weight_common_words_spacy_thresh_0.80",
            "sum_prob_weight_common_words_spacy_thresh_0.90",
            "sum_prob_weight_common_words_spacy_thresh_0.95",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.20",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.30",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.40",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.50",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.60",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.70",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.80",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.90",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.95",
            "n_sim_lemm_spacy",
            "n_sim_lemm_stop_spacy",
            "q1_words_not_in_word2vec",
            "q2_words_not_in_word2vec",
            "uncommon_not_in_word2vec",
            "clean_lemm_stem_len1",
            "clean_lemm_stem_len2",
            "clean_lemm_stem_word_len1",
            "clean_lemm_stem_word_len2",
            "clean_lemm_stem_match_ratio",
            "clean_lemm_stem_word_match",
            "clean_lemm_stem_word_match_idf",
            "clean_lemm_stem_tfidf_sum1",
            "clean_lemm_stem_tfidf_sum2",
            "clean_lemm_stem_tfidf_mean1",
            "clean_lemm_stem_tfidf_mean2",
            "clean_lemm_stem_tfidf_len1",
            "clean_lemm_stem_tfidf_len2"
        ]
    },
    "results": [
        {
            "accuracy": 0.9400994788711535,
            "auc": 0.9743300242788768,
            "f1_score": 0.816088420482216,
            "log_loss": 0.14447888939508266,
            "precision": 0.8775972283955111,
            "pred_mean": 0.17935923435255738,
            "recall": 0.7626369209124712,
            "train_log_loss": 0.1106602149041864
        },
        {
            "accuracy": 0.9406072636227896,
            "auc": 0.9746044952239674,
            "f1_score": 0.8183280161910402,
            "log_loss": 0.1441332976909786,
            "precision": 0.8762424724859623,
            "pred_mean": 0.18066105253618145,
            "recall": 0.7675945466117308,
            "train_log_loss": 0.11083877437247747
        },
        {
            "accuracy": 0.9410906557286189,
            "auc": 0.9748542067810553,
            "f1_score": 0.8195228277012294,
            "log_loss": 0.142864277274281,
            "precision": 0.8791186861346892,
            "pred_mean": 0.18018916070145993,
            "recall": 0.767494054198908,
            "train_log_loss": 0.11110202184868165
        },
        {
            "accuracy": 0.939785430920089,
            "auc": 0.9744297876779319,
            "f1_score": 0.8157871773174952,
            "log_loss": 0.14438792914359308,
            "precision": 0.8736565507505066,
            "pred_mean": 0.18048736663602108,
            "recall": 0.7651078654696503,
            "train_log_loss": 0.11088349031190854
        },
        {
            "accuracy": 0.9408095642363072,
            "auc": 0.9750012445805754,
            "f1_score": 0.8185721737249922,
            "log_loss": 0.1427737067216558,
            "precision": 0.8785676813317869,
            "pred_mean": 0.1795721378854337,
            "recall": 0.7662468176336594,
            "train_log_loss": 0.11141961949022076
        }
    ],
    "sum_log_loss": 0.7186381002255912
}
{
    "config": {
        "data_prefix": "data/input/",
        "features": [
            0,
            1,
            2,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            16,
            18,
            21,
            22,
            28,
            30,
            31,
            32,
            44,
            45,
            46,
            47,
            57,
            60,
            64,
            75,
            76,
            77,
            78,
            79,
            80,
            81,
            82,
            83,
            84,
            85,
            86,
            91,
            92,
            93,
            109,
            110,
            111,
            112,
            117,
            118,
            119,
            137,
            145,
            146,
            151,
            152,
            153,
            154,
            155,
            156,
            157,
            158,
            159,
            160,
            161,
            162,
            163,
            164,
            165,
            166,
            167,
            168,
            1000,
            1001,
            1002,
            1003,
            1004,
            1005,
            1006,
            1007,
            1008,
            1013,
            1018,
            1026,
            1027,
            1028,
            1029,
            1030
        ],
        "model": {
            "params": {
                "booster": {
                    "colsample_bytree": 0.5,
                    "eta": 0.02,
                    "eval_metric": "logloss",
                    "gamma": 1,
                    "lambda": 0.1,
                    "max_depth": 7,
                    "min_child_weight": 10,
                    "objective": "binary:logistic",
                    "seed": 87978979,
                    "silent": 0,
                    "subsample": 0.7
                },
                "train": {
                    "early_stopping_rounds": 50,
                    "num_boost_round": 3000,
                    "verbose_eval": 50
                }
            },
            "path": "models/1000_xgb_cross.py",
            "target_positive_ratio": 0.17426506525171756
        },
        "takapt_features": [
            "z_noun_match",
            "z_word_match",
            "z_word_match_idf",
            "z_n_sim",
            "common_words_lemm",
            "n_sim_lemm",
            "n_sim_lemm_stop",
            "s2v_sum_dist",
            "s2v_ave_dist",
            "sum_prob_weight_common_words",
            "sum_prob_weight_uncommon_words",
            "top_similarity",
            "min_sim",
            "max_sim",
            "common_bigrams_clean_lemm",
            "jaccard_common_bigrams_clean_lemm",
            "nazo_common_bigrams_clean_lemm",
            "sum_weight_common_bigrams",
            "sum_weight_common_bigrams_limit3",
            "common_ngrams_clean_lemm",
            "jaccard_common_ngrams_clean_lemm",
            "nazo_common_ngrams_clean_lemm",
            "clean_lemm_wmd",
            "bleu_clean_lemm_stem_q1q2",
            "bleu_clean_lemm_stem_q2q1",
            "bleu_clean_lemm_q1q2",
            "bleu_clean_lemm_q2q1",
            "norm_sum_prob_weight_common_words",
            "sum_prob_weight_common_words_thresh_0.20",
            "sum_prob_weight_common_words_thresh_0.30",
            "sum_prob_weight_common_words_thresh_0.40",
            "sum_prob_weight_common_words_thresh_0.50",
            "sum_prob_weight_common_words_thresh_0.60",
            "sum_prob_weight_common_words_thresh_0.70",
            "sum_prob_weight_common_words_thresh_0.80",
            "sum_prob_weight_common_words_thresh_0.90",
            "sum_prob_weight_common_words_thresh_0.95",
            "sum_prob_weight_uncommon_words_thresh_0.20",
            "sum_prob_weight_uncommon_words_thresh_0.30",
            "sum_prob_weight_uncommon_words_thresh_0.40",
            "sum_prob_weight_uncommon_words_thresh_0.50",
            "sum_prob_weight_uncommon_words_thresh_0.60",
            "sum_prob_weight_uncommon_words_thresh_0.70",
            "sum_prob_weight_uncommon_words_thresh_0.80",
            "sum_prob_weight_uncommon_words_thresh_0.90",
            "sum_prob_weight_uncommon_words_thresh_0.95",
            "sum_prob_weight_common_words_spacy_thresh_0.20",
            "sum_prob_weight_common_words_spacy_thresh_0.30",
            "sum_prob_weight_common_words_spacy_thresh_0.40",
            "sum_prob_weight_common_words_spacy_thresh_0.50",
            "sum_prob_weight_common_words_spacy_thresh_0.60",
            "sum_prob_weight_common_words_spacy_thresh_0.70",
            "sum_prob_weight_common_words_spacy_thresh_0.80",
            "sum_prob_weight_common_words_spacy_thresh_0.90",
            "sum_prob_weight_common_words_spacy_thresh_0.95",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.20",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.30",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.40",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.50",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.60",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.70",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.80",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.90",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.95",
            "n_sim_lemm_spacy",
            "n_sim_lemm_stop_spacy",
            "q1_words_not_in_word2vec",
            "q2_words_not_in_word2vec",
            "uncommon_not_in_word2vec",
            "clean_lemm_stem_len1",
            "clean_lemm_stem_len2",
            "clean_lemm_stem_word_len1",
            "clean_lemm_stem_word_len2",
            "clean_lemm_stem_match_ratio",
            "clean_lemm_stem_word_match",
            "clean_lemm_stem_word_match_idf",
            "clean_lemm_stem_tfidf_sum1",
            "clean_lemm_stem_tfidf_sum2",
            "clean_lemm_stem_tfidf_mean1",
            "clean_lemm_stem_tfidf_mean2",
            "clean_lemm_stem_tfidf_len1",
            "clean_lemm_stem_tfidf_len2"
        ]
    },
    "results": [
        {
            "accuracy": 0.9407308808801349,
            "auc": 0.9749318471998712,
            "f1_score": 0.8203575117013002,
            "log_loss": 0.14322201146383823,
            "precision": 0.8693757379824322,
            "pred_mean": 0.18277967880034274,
            "recall": 0.7765718688239038,
            "train_log_loss": 0.08697535278060273
        },
        {
            "accuracy": 0.9405685363659005,
            "auc": 0.9752218745764195,
            "f1_score": 0.8209545980673653,
            "log_loss": 0.14283129440850545,
            "precision": 0.8641591344394517,
            "pred_mean": 0.1841602270062983,
            "recall": 0.7818644692325729,
            "train_log_loss": 0.0871364640808435
        },
        {
            "accuracy": 0.9415609550289705,
            "auc": 0.9754558145946429,
            "f1_score": 0.8234250289897415,
            "log_loss": 0.14181522537010996,
            "precision": 0.8696105587868755,
            "pred_mean": 0.18392576907792857,
            "recall": 0.7818979667035139,
            "train_log_loss": 0.08749437488715622
        },
        {
            "accuracy": 0.9398801876313108,
            "auc": 0.9751074644453878,
            "f1_score": 0.8188392608892704,
            "log_loss": 0.14296126973168788,
            "precision": 0.8621403621093632,
            "pred_mean": 0.1841873426954976,
            "recall": 0.7796797534503551,
            "train_log_loss": 0.08690659439788734
        },
        {
            "accuracy": 0.9410327476068676,
            "auc": 0.9756152339582024,
            "f1_score": 0.8220448534444605,
            "log_loss": 0.14166143689592628,
            "precision": 0.8669583952435904,
            "pred_mean": 0.18336039108334318,
            "recall": 0.7815556746616642,
            "train_log_loss": 0.08781178969170746
        }
    ],
    "sum_log_loss": 0.7124912378700677
}
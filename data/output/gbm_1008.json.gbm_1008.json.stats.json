{
    "config": {
        "data_prefix": "data/input/",
        "features": [
            0,
            1,
            2,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            16,
            18,
            21,
            22,
            28,
            30,
            31,
            32,
            44,
            45,
            46,
            47,
            57,
            60,
            64,
            75,
            76,
            77,
            78,
            79,
            80,
            81,
            82,
            83,
            84,
            85,
            86,
            91,
            92,
            93,
            109,
            110,
            111,
            112,
            117,
            118,
            119,
            137,
            145,
            146,
            151,
            152,
            153,
            154,
            155,
            156,
            157,
            158,
            159,
            160,
            161,
            162,
            163,
            164,
            165,
            166,
            167,
            168,
            1000,
            1001,
            1002,
            1010,
            1011
        ],
        "model": {
            "params": {
                "booster": {
                    "bagging_fraction": 0.7,
                    "bagging_freq": 5,
                    "bagging_seed": 3,
                    "categorical_column": [],
                    "feature_fraction": 0.7,
                    "feature_fraction_seed": 2,
                    "lambda_l2": 5,
                    "learning_rate": 0.02,
                    "max_bin": 255,
                    "metric": "binary_logloss",
                    "num_leaves": 256,
                    "objective": "binary",
                    "task": "train",
                    "verbose": 1
                },
                "train": {
                    "early_stopping_rounds": 50,
                    "num_boost_round": 1000,
                    "verbose_eval": 10
                }
            },
            "path": "models/2_lightgbm.py",
            "target_positive_ratio": 0.17426506525171756
        }
    },
    "feature_importance": {
        "dep_2grams_common_ratio_stop": 2165,
        "dep_2grams_stop_sum_tfidf_q1": 1651,
        "dep_2grams_stop_sum_tfidf_q2": 1611,
        "dep_2grams_stop_tfidf_cosine": 2219,
        "dep_2grams_sum_tfidf_q1": 1226,
        "dep_2grams_sum_tfidf_q2": 1336,
        "dep_2grams_tfidf_cosine": 2560,
        "dep_depth_limit_in_q1_words_ratio_glove": 83,
        "dep_depth_limit_in_q1_words_ratio_glove.1": 5,
        "dep_depth_limit_in_q2_words_ratio_glove": 38,
        "dep_depth_limit_in_q2_words_ratio_glove.1": 19,
        "dep_depth_limit_wmd_glove": 2980,
        "dep_depth_limit_wmd_glove.1": 3031,
        "f0": 2333,
        "f1": 2650,
        "f10": 1441,
        "f109": 1650,
        "f11": 2383,
        "f110": 531,
        "f111": 2770,
        "f112": 2442,
        "f117.q1_freq": 775,
        "f117.q2_freq": 737,
        "f118": 2964,
        "f119": 2309,
        "f12": 1148,
        "f13": 2208,
        "f137.0": 1565,
        "f137.1": 1076,
        "f137.10": 1488,
        "f137.11": 1094,
        "f137.12": 1094,
        "f137.13": 877,
        "f137.14": 1003,
        "f137.15": 1424,
        "f137.16": 1233,
        "f137.17": 1130,
        "f137.18": 1645,
        "f137.19": 2083,
        "f137.2": 1143,
        "f137.3": 873,
        "f137.4": 1038,
        "f137.5": 1375,
        "f137.6": 1328,
        "f137.7": 1295,
        "f137.8": 1674,
        "f137.9": 2091,
        "f14": 883,
        "f145": 187,
        "f146": 1002,
        "f151.0": 114,
        "f151.1": 299,
        "f151.10": 35,
        "f151.11": 47,
        "f151.12": 52,
        "f151.13": 39,
        "f151.14": 67,
        "f151.15": 41,
        "f151.16": 30,
        "f151.17": 33,
        "f151.18": 41,
        "f151.19": 32,
        "f151.2": 191,
        "f151.20": 39,
        "f151.21": 34,
        "f151.22": 27,
        "f151.23": 27,
        "f151.24": 34,
        "f151.25": 38,
        "f151.26": 35,
        "f151.27": 26,
        "f151.28": 23,
        "f151.29": 25,
        "f151.3": 223,
        "f151.30": 43,
        "f151.31": 59,
        "f151.4": 178,
        "f151.5": 64,
        "f151.6": 64,
        "f151.7": 95,
        "f151.8": 95,
        "f151.9": 43,
        "f152": 773,
        "f153": 1443,
        "f154": 1719,
        "f155": 2039,
        "f156": 1222,
        "f157": 589,
        "f158": 547,
        "f159": 2553,
        "f16": 1741,
        "f160": 2727,
        "f161": 1631,
        "f162": 1186,
        "f163": 2147,
        "f164": 1488,
        "f165": 2173,
        "f166": 2594,
        "f167": 2502,
        "f168": 1840,
        "f18": 1706,
        "f2": 395,
        "f21": 1549,
        "f22": 2078,
        "f28": 2772,
        "f30": 395,
        "f31": 1833,
        "f32": 2300,
        "f4": 1165,
        "f44": 2622,
        "f45": 2869,
        "f46": 2365,
        "f47": 522,
        "f5": 1348,
        "f57.0": 1934,
        "f57.1": 1604,
        "f57.10": 1997,
        "f57.11": 1681,
        "f57.12": 1901,
        "f57.13": 1491,
        "f57.14": 1836,
        "f57.15": 1989,
        "f57.16": 1337,
        "f57.17": 1735,
        "f57.18": 1774,
        "f57.19": 1525,
        "f57.2": 1809,
        "f57.3": 1522,
        "f57.4": 1826,
        "f57.5": 2058,
        "f57.6": 1426,
        "f57.7": 1775,
        "f57.8": 1796,
        "f57.9": 1462,
        "f6": 1942,
        "f60.0": 341,
        "f60.1": 1354,
        "f60.10": 341,
        "f60.11": 1377,
        "f60.12": 1427,
        "f60.13": 1243,
        "f60.14": 1455,
        "f60.15": 1295,
        "f60.16": 1616,
        "f60.17": 1706,
        "f60.18": 1818,
        "f60.19": 1860,
        "f60.2": 1550,
        "f60.3": 1220,
        "f60.4": 1498,
        "f60.5": 1213,
        "f60.6": 1513,
        "f60.7": 1691,
        "f60.8": 1915,
        "f60.9": 1795,
        "f64.0": 1794,
        "f64.1": 1471,
        "f64.10": 1697,
        "f64.11": 1282,
        "f64.12": 1502,
        "f64.13": 1505,
        "f64.14": 1633,
        "f64.15": 1639,
        "f64.16": 1634,
        "f64.17": 1447,
        "f64.18": 1641,
        "f64.19": 1664,
        "f64.2": 1479,
        "f64.3": 1566,
        "f64.4": 1541,
        "f64.5": 1809,
        "f64.6": 1631,
        "f64.7": 1505,
        "f64.8": 1602,
        "f64.9": 1782,
        "f7": 413,
        "f75": 1248,
        "f76": 1154,
        "f77": 1893,
        "f78": 1796,
        "f79": 1743,
        "f8": 473,
        "f80": 1712,
        "f81": 1823,
        "f82": 1766,
        "f83": 1173,
        "f84": 1275,
        "f85": 933,
        "f86": 1038,
        "f9": 1275,
        "f91": 2830,
        "f92": 2960,
        "f93": 2131
    },
    "results": {
        "accuracy": 0.9389135524469542,
        "auc": 0.9740986100985771,
        "f1_score": 0.8172359564595807,
        "log_loss": 0.14588836648960127,
        "precision": 0.8537622454742279,
        "pred_mean": 0.18696946946682375,
        "recall": 0.7837068301343248,
        "train_log_loss": 0.07420800808502653
    }
}
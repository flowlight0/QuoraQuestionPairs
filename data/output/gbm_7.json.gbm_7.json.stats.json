{
    "config": {
        "comment": "gbm_3 with replacing feature 60 with 67",
        "data_prefix": "data/input/",
        "features": [
            0,
            1,
            2,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            16,
            18,
            21,
            22,
            25,
            26,
            28,
            30,
            31,
            32,
            44,
            45,
            46,
            47,
            67
        ],
        "model": {
            "params": {
                "booster": {
                    "categorical_column": [],
                    "learning_rate": 0.02,
                    "max_bin": 255,
                    "metric": "binary_logloss",
                    "num_leaves": 16,
                    "objective": "binary",
                    "task": "train",
                    "verbose": 1
                },
                "train": {
                    "early_stopping_rounds": 50,
                    "num_boost_round": 400,
                    "verbose_eval": 10
                }
            },
            "path": "models/2_lightgbm.py",
            "target_positive_ratio": 0.17426506525171756
        }
    },
    "feature_importance": {
        "f0": 583,
        "f1": 55,
        "f10": 135,
        "f11": 253,
        "f12": 62,
        "f13": 61,
        "f14": 117,
        "f16": 40,
        "f18": 136,
        "f2": 114,
        "f21": 164,
        "f22": 199,
        "f25": 62,
        "f26": 82,
        "f28": 5,
        "f30": 121,
        "f31": 15,
        "f32": 146,
        "f4": 53,
        "f44": 247,
        "f45": 49,
        "f46": 297,
        "f47": 23,
        "f5": 65,
        "f6": 34,
        "f67.0": 44,
        "f67.1": 32,
        "f67.10": 4,
        "f67.11": 29,
        "f67.12": 69,
        "f67.13": 28,
        "f67.14": 19,
        "f67.15": 20,
        "f67.16": 26,
        "f67.17": 1,
        "f67.18": 14,
        "f67.19": 10,
        "f67.2": 8,
        "f67.20": 31,
        "f67.21": 19,
        "f67.22": 2,
        "f67.23": 99,
        "f67.24": 47,
        "f67.25": 14,
        "f67.26": 7,
        "f67.27": 9,
        "f67.28": 7,
        "f67.29": 54,
        "f67.3": 85,
        "f67.30": 13,
        "f67.31": 0,
        "f67.32": 15,
        "f67.33": 31,
        "f67.34": 26,
        "f67.35": 12,
        "f67.36": 35,
        "f67.37": 81,
        "f67.38": 45,
        "f67.39": 5,
        "f67.4": 107,
        "f67.40": 7,
        "f67.41": 55,
        "f67.42": 11,
        "f67.43": 18,
        "f67.44": 11,
        "f67.45": 27,
        "f67.46": 53,
        "f67.47": 26,
        "f67.48": 12,
        "f67.49": 49,
        "f67.5": 75,
        "f67.50": 21,
        "f67.51": 48,
        "f67.52": 21,
        "f67.53": 46,
        "f67.54": 48,
        "f67.55": 112,
        "f67.56": 39,
        "f67.57": 30,
        "f67.58": 18,
        "f67.59": 66,
        "f67.6": 31,
        "f67.60": 2,
        "f67.61": 19,
        "f67.62": 44,
        "f67.63": 15,
        "f67.64": 41,
        "f67.65": 49,
        "f67.66": 7,
        "f67.67": 2,
        "f67.68": 32,
        "f67.69": 7,
        "f67.7": 40,
        "f67.70": 24,
        "f67.71": 10,
        "f67.72": 3,
        "f67.73": 82,
        "f67.74": 11,
        "f67.75": 13,
        "f67.76": 6,
        "f67.77": 36,
        "f67.78": 3,
        "f67.79": 35,
        "f67.8": 27,
        "f67.80": 28,
        "f67.81": 2,
        "f67.82": 9,
        "f67.83": 14,
        "f67.84": 11,
        "f67.85": 5,
        "f67.86": 42,
        "f67.87": 24,
        "f67.88": 22,
        "f67.89": 14,
        "f67.9": 24,
        "f67.90": 11,
        "f67.91": 33,
        "f67.92": 9,
        "f67.93": 9,
        "f67.94": 31,
        "f67.95": 16,
        "f67.96": 38,
        "f67.97": 32,
        "f67.98": 12,
        "f67.99": 34,
        "f7": 12,
        "f8": 4,
        "f9": 66
    },
    "results": {
        "accuracy": 0.8594880992152105,
        "auc": 0.897680755909238,
        "f1_score": 0.4776451106850271,
        "log_loss": 0.2883985857525255,
        "precision": 0.6781538080801831,
        "pred_mean": 0.17583379073823424,
        "recall": 0.36864763057881816
    }
}
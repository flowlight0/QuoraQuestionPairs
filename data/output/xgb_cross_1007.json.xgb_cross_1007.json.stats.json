{
    "config": {
        "data_prefix": "data/input/",
        "features": [
            0,
            1,
            2,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            16,
            18,
            21,
            22,
            28,
            30,
            31,
            32,
            44,
            45,
            46,
            47,
            57,
            60,
            64,
            75,
            76,
            77,
            78,
            79,
            80,
            81,
            82,
            83,
            84,
            85,
            86,
            91,
            92,
            93,
            109,
            110,
            111,
            112,
            117,
            118,
            119,
            137,
            145,
            146,
            151,
            152,
            153,
            154,
            155,
            156,
            157,
            158,
            159,
            160,
            161,
            162,
            163,
            164,
            165,
            166,
            167,
            168,
            1000,
            1001,
            1002,
            1003,
            1004,
            1005,
            1006,
            1007,
            1008,
            1013,
            1018,
            1026,
            1027,
            1028,
            1029,
            1030
        ],
        "model": {
            "params": {
                "booster": {
                    "colsample_bytree": 0.7,
                    "eta": 0.08,
                    "eval_metric": "logloss",
                    "gamma": 0,
                    "lambda": 1,
                    "max_depth": 8,
                    "min_child_weight": 100,
                    "objective": "binary:logistic",
                    "seed": 87978979,
                    "silent": 0,
                    "subsample": 0.7
                },
                "train": {
                    "early_stopping_rounds": 50,
                    "num_boost_round": 2000,
                    "verbose_eval": 50
                }
            },
            "path": "models/1000_xgb_cross.py",
            "target_positive_ratio": 0.17426506525171756
        },
        "takapt_features": [
            "z_noun_match",
            "z_word_match",
            "z_word_match_idf",
            "z_n_sim",
            "common_words_lemm",
            "n_sim_lemm",
            "n_sim_lemm_stop",
            "s2v_sum_dist",
            "s2v_ave_dist",
            "sum_prob_weight_common_words",
            "sum_prob_weight_uncommon_words",
            "top_similarity",
            "min_sim",
            "max_sim",
            "common_bigrams_clean_lemm",
            "jaccard_common_bigrams_clean_lemm",
            "nazo_common_bigrams_clean_lemm",
            "sum_weight_common_bigrams",
            "sum_weight_common_bigrams_limit3",
            "common_ngrams_clean_lemm",
            "jaccard_common_ngrams_clean_lemm",
            "nazo_common_ngrams_clean_lemm",
            "clean_lemm_wmd",
            "bleu_clean_lemm_stem_q1q2",
            "bleu_clean_lemm_stem_q2q1",
            "bleu_clean_lemm_q1q2",
            "bleu_clean_lemm_q2q1",
            "norm_sum_prob_weight_common_words",
            "sum_prob_weight_common_words_thresh_0.20",
            "sum_prob_weight_common_words_thresh_0.30",
            "sum_prob_weight_common_words_thresh_0.40",
            "sum_prob_weight_common_words_thresh_0.50",
            "sum_prob_weight_common_words_thresh_0.60",
            "sum_prob_weight_common_words_thresh_0.70",
            "sum_prob_weight_common_words_thresh_0.80",
            "sum_prob_weight_common_words_thresh_0.90",
            "sum_prob_weight_common_words_thresh_0.95",
            "sum_prob_weight_uncommon_words_thresh_0.20",
            "sum_prob_weight_uncommon_words_thresh_0.30",
            "sum_prob_weight_uncommon_words_thresh_0.40",
            "sum_prob_weight_uncommon_words_thresh_0.50",
            "sum_prob_weight_uncommon_words_thresh_0.60",
            "sum_prob_weight_uncommon_words_thresh_0.70",
            "sum_prob_weight_uncommon_words_thresh_0.80",
            "sum_prob_weight_uncommon_words_thresh_0.90",
            "sum_prob_weight_uncommon_words_thresh_0.95",
            "sum_prob_weight_common_words_spacy_thresh_0.20",
            "sum_prob_weight_common_words_spacy_thresh_0.30",
            "sum_prob_weight_common_words_spacy_thresh_0.40",
            "sum_prob_weight_common_words_spacy_thresh_0.50",
            "sum_prob_weight_common_words_spacy_thresh_0.60",
            "sum_prob_weight_common_words_spacy_thresh_0.70",
            "sum_prob_weight_common_words_spacy_thresh_0.80",
            "sum_prob_weight_common_words_spacy_thresh_0.90",
            "sum_prob_weight_common_words_spacy_thresh_0.95",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.20",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.30",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.40",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.50",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.60",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.70",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.80",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.90",
            "sum_prob_weight_uncommon_words_spacy_thresh_0.95",
            "n_sim_lemm_spacy",
            "n_sim_lemm_stop_spacy",
            "q1_words_not_in_word2vec",
            "q2_words_not_in_word2vec",
            "uncommon_not_in_word2vec",
            "clean_lemm_stem_len1",
            "clean_lemm_stem_len2",
            "clean_lemm_stem_word_len1",
            "clean_lemm_stem_word_len2",
            "clean_lemm_stem_match_ratio",
            "clean_lemm_stem_word_match",
            "clean_lemm_stem_word_match_idf",
            "clean_lemm_stem_tfidf_sum1",
            "clean_lemm_stem_tfidf_sum2",
            "clean_lemm_stem_tfidf_mean1",
            "clean_lemm_stem_tfidf_mean2",
            "clean_lemm_stem_tfidf_len1",
            "clean_lemm_stem_tfidf_len2"
        ]
    },
    "results": [
        {
            "accuracy": 0.9393589506773338,
            "auc": 0.9743351277734987,
            "f1_score": 0.8175710995970912,
            "log_loss": 0.14484609934433984,
            "precision": 0.8592431769122163,
            "pred_mean": 0.18268476975114434,
            "recall": 0.7797541285632935,
            "train_log_loss": 0.09134728866365582
        },
        {
            "accuracy": 0.939638677277369,
            "auc": 0.9744321903831218,
            "f1_score": 0.8182468977091348,
            "log_loss": 0.14521532461991976,
            "precision": 0.8608190771187652,
            "pred_mean": 0.18313723045647848,
            "recall": 0.7796871336214116,
            "train_log_loss": 0.09736045380687504
        },
        {
            "accuracy": 0.9404656161080219,
            "auc": 0.9748559363289372,
            "f1_score": 0.8209417586679473,
            "log_loss": 0.14325023852501623,
            "precision": 0.8625811322996714,
            "pred_mean": 0.18316021578166997,
            "recall": 0.7831373731283288,
            "train_log_loss": 0.09336023680757279
        },
        {
            "accuracy": 0.9385511038698451,
            "auc": 0.9742586552174215,
            "f1_score": 0.8153917926226079,
            "log_loss": 0.1452048770022965,
            "precision": 0.8556618903352183,
            "pred_mean": 0.18335316788259254,
            "recall": 0.7787417928447006,
            "train_log_loss": 0.0971958316705388
        },
        {
            "accuracy": 0.939972882549859,
            "auc": 0.9747686203149155,
            "f1_score": 0.8186915992941756,
            "log_loss": 0.14382329356052087,
            "precision": 0.8642407507279414,
            "pred_mean": 0.18176632829181022,
            "recall": 0.7777033364598687,
            "train_log_loss": 0.09977177097267535
        }
    ],
    "sum_log_loss": 0.7223398330520931
}
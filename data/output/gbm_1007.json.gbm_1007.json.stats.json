{
    "config": {
        "data_prefix": "data/input/",
        "features": [
            0,
            1,
            2,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            16,
            18,
            21,
            22,
            28,
            30,
            31,
            32,
            44,
            45,
            46,
            47,
            57,
            60,
            64,
            75,
            76,
            77,
            78,
            79,
            80,
            81,
            82,
            83,
            84,
            85,
            86,
            91,
            92,
            93,
            109,
            110,
            111,
            112,
            117,
            118,
            119,
            137,
            145,
            146,
            151,
            152,
            153,
            154,
            155,
            156,
            157,
            158,
            159,
            160,
            161,
            162,
            163,
            164,
            165,
            166,
            167,
            168,
            1000,
            1001,
            1002,
            1010,
            1011
        ],
        "model": {
            "params": {
                "booster": {
                    "bagging_fraction": 0.7,
                    "bagging_freq": 5,
                    "bagging_seed": 3,
                    "categorical_column": [],
                    "feature_fraction": 0.7,
                    "feature_fraction_seed": 2,
                    "lambda_l2": 1,
                    "learning_rate": 0.02,
                    "max_bin": 255,
                    "metric": "binary_logloss",
                    "num_leaves": 256,
                    "objective": "binary",
                    "task": "train",
                    "verbose": 1
                },
                "train": {
                    "early_stopping_rounds": 50,
                    "num_boost_round": 1000,
                    "verbose_eval": 10
                }
            },
            "path": "models/2_lightgbm.py",
            "target_positive_ratio": 0.17426506525171756
        }
    },
    "feature_importance": {
        "dep_2grams_common_ratio_stop": 2155,
        "dep_2grams_stop_sum_tfidf_q1": 1729,
        "dep_2grams_stop_sum_tfidf_q2": 1612,
        "dep_2grams_stop_tfidf_cosine": 2361,
        "dep_2grams_sum_tfidf_q1": 1218,
        "dep_2grams_sum_tfidf_q2": 1302,
        "dep_2grams_tfidf_cosine": 2607,
        "dep_depth_limit_in_q1_words_ratio_glove": 89,
        "dep_depth_limit_in_q1_words_ratio_glove.1": 7,
        "dep_depth_limit_in_q2_words_ratio_glove": 57,
        "dep_depth_limit_in_q2_words_ratio_glove.1": 29,
        "dep_depth_limit_wmd_glove": 2861,
        "dep_depth_limit_wmd_glove.1": 2944,
        "f0": 2292,
        "f1": 2622,
        "f10": 1507,
        "f109": 1769,
        "f11": 2354,
        "f110": 505,
        "f111": 2786,
        "f112": 2448,
        "f117.q1_freq": 748,
        "f117.q2_freq": 685,
        "f118": 2944,
        "f119": 2195,
        "f12": 1196,
        "f13": 2205,
        "f137.0": 1546,
        "f137.1": 1111,
        "f137.10": 1439,
        "f137.11": 1093,
        "f137.12": 1169,
        "f137.13": 907,
        "f137.14": 1050,
        "f137.15": 1369,
        "f137.16": 1222,
        "f137.17": 1183,
        "f137.18": 1602,
        "f137.19": 2013,
        "f137.2": 1176,
        "f137.3": 880,
        "f137.4": 977,
        "f137.5": 1400,
        "f137.6": 1331,
        "f137.7": 1301,
        "f137.8": 1607,
        "f137.9": 1909,
        "f14": 838,
        "f145": 196,
        "f146": 1030,
        "f151.0": 112,
        "f151.1": 298,
        "f151.10": 43,
        "f151.11": 50,
        "f151.12": 35,
        "f151.13": 43,
        "f151.14": 62,
        "f151.15": 43,
        "f151.16": 27,
        "f151.17": 28,
        "f151.18": 43,
        "f151.19": 33,
        "f151.2": 176,
        "f151.20": 43,
        "f151.21": 35,
        "f151.22": 34,
        "f151.23": 21,
        "f151.24": 29,
        "f151.25": 44,
        "f151.26": 44,
        "f151.27": 24,
        "f151.28": 32,
        "f151.29": 24,
        "f151.3": 224,
        "f151.30": 35,
        "f151.31": 57,
        "f151.4": 163,
        "f151.5": 68,
        "f151.6": 80,
        "f151.7": 92,
        "f151.8": 100,
        "f151.9": 50,
        "f152": 801,
        "f153": 1469,
        "f154": 1731,
        "f155": 1959,
        "f156": 1283,
        "f157": 561,
        "f158": 529,
        "f159": 2571,
        "f16": 1642,
        "f160": 2816,
        "f161": 1620,
        "f162": 1178,
        "f163": 2208,
        "f164": 1521,
        "f165": 2115,
        "f166": 2687,
        "f167": 2525,
        "f168": 1820,
        "f18": 1676,
        "f2": 389,
        "f21": 1492,
        "f22": 2040,
        "f28": 2770,
        "f30": 397,
        "f31": 1860,
        "f32": 2272,
        "f4": 1233,
        "f44": 2660,
        "f45": 2782,
        "f46": 2353,
        "f47": 501,
        "f5": 1364,
        "f57.0": 1950,
        "f57.1": 1709,
        "f57.10": 2083,
        "f57.11": 1759,
        "f57.12": 1848,
        "f57.13": 1502,
        "f57.14": 1883,
        "f57.15": 1907,
        "f57.16": 1328,
        "f57.17": 1674,
        "f57.18": 1789,
        "f57.19": 1482,
        "f57.2": 1907,
        "f57.3": 1446,
        "f57.4": 1818,
        "f57.5": 1956,
        "f57.6": 1429,
        "f57.7": 1775,
        "f57.8": 1847,
        "f57.9": 1456,
        "f6": 1924,
        "f60.0": 348,
        "f60.1": 1408,
        "f60.10": 344,
        "f60.11": 1343,
        "f60.12": 1437,
        "f60.13": 1239,
        "f60.14": 1333,
        "f60.15": 1277,
        "f60.16": 1552,
        "f60.17": 1681,
        "f60.18": 1900,
        "f60.19": 1835,
        "f60.2": 1563,
        "f60.3": 1305,
        "f60.4": 1508,
        "f60.5": 1258,
        "f60.6": 1531,
        "f60.7": 1682,
        "f60.8": 1888,
        "f60.9": 1763,
        "f64.0": 1724,
        "f64.1": 1535,
        "f64.10": 1641,
        "f64.11": 1343,
        "f64.12": 1528,
        "f64.13": 1524,
        "f64.14": 1627,
        "f64.15": 1645,
        "f64.16": 1562,
        "f64.17": 1405,
        "f64.18": 1630,
        "f64.19": 1614,
        "f64.2": 1542,
        "f64.3": 1579,
        "f64.4": 1588,
        "f64.5": 1897,
        "f64.6": 1713,
        "f64.7": 1511,
        "f64.8": 1614,
        "f64.9": 1838,
        "f7": 416,
        "f75": 1250,
        "f76": 1264,
        "f77": 1873,
        "f78": 1738,
        "f79": 1794,
        "f8": 449,
        "f80": 1824,
        "f81": 1775,
        "f82": 1769,
        "f83": 1161,
        "f84": 1293,
        "f85": 922,
        "f86": 977,
        "f9": 1237,
        "f91": 2861,
        "f92": 2935,
        "f93": 2142
    },
    "results": {
        "accuracy": 0.9384539454986323,
        "auc": 0.973758610604339,
        "f1_score": 0.8157860039649601,
        "log_loss": 0.14650482324928432,
        "precision": 0.8526250899368912,
        "pred_mean": 0.18675436214074329,
        "recall": 0.7819984591163367,
        "train_log_loss": 0.06948062878292312
    }
}